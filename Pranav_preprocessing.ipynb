{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10957678,
          "sourceType": "datasetVersion",
          "datasetId": 6816825
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook5fff8a243b",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dope232/GenAI-Project/blob/main/Pranav_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T11:48:08.817669Z",
          "iopub.execute_input": "2025-03-19T11:48:08.817974Z",
          "iopub.status.idle": "2025-03-19T11:48:09.715394Z",
          "shell.execute_reply.started": "2025-03-19T11:48:08.817945Z",
          "shell.execute_reply": "2025-03-19T11:48:09.71448Z"
        },
        "id": "zzXpebS1vldK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-nlp-library --quiet\n",
        "\n",
        "!pip install langchain langchain_community faiss-cpu tqdm pandas numpy torch transformers --quiet"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-19T11:48:13.95537Z",
          "iopub.execute_input": "2025-03-19T11:48:13.955659Z",
          "iopub.status.idle": "2025-03-19T11:54:55.142518Z",
          "shell.execute_reply.started": "2025-03-19T11:48:13.955635Z",
          "shell.execute_reply": "2025-03-19T11:54:55.14154Z"
        },
        "id": "y__hySXCvldL",
        "outputId": "39fe65d7-87ce-4287-a30a-afb25328a9cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d8afc5d8f40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/indic-nlp-library/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d8afc5d9270>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/indic-nlp-library/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d8afc5d9510>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/indic-nlp-library/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d8afc5d96c0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/indic-nlp-library/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d8afc5d9870>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/indic-nlp-library/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement indic-nlp-library (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for indic-nlp-library\u001b[0m\u001b[31m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b016393de70>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/langchain-community/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b016393e1a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/langchain-community/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b016393e440>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/langchain-community/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b016393e5f0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/langchain-community/\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b016393e7a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/langchain-community/\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement langchain_community (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for langchain_community\u001b[0m\u001b[31m\n\u001b[0m",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from indic_transliteration import sanscript\n",
        "from indic_transliteration.sanscript import SchemeMap, SCHEMES, transliterate\n",
        "import json\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "from tqdm.notebook import tqdm\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import pipeline, AutoModelForCausalLM, T5ForConditionalGeneration, AutoTokenizer\n",
        "import time\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "    # For some operations, enables faster but slightly less precise computation\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "def load_movie_dialogues(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def transliterate_to_devanagari(text):\n",
        "    try:\n",
        "\n",
        "        if text.isupper() and len(text.split()) == 1:\n",
        "            return text\n",
        "\n",
        "        devanagari_text = transliterate(text, sanscript.ITRANS, sanscript.DEVANAGARI)\n",
        "        return devanagari_text\n",
        "    except Exception as e:\n",
        "        print(f\"Transliteration error: {e}\")\n",
        "        return text\n",
        "\n",
        "\n",
        "class DialogueSceneDataset(Dataset):\n",
        "    def __init__(self, scenes):\n",
        "        self.scenes = scenes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.scenes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.scenes[idx]\n",
        "\n",
        "\n",
        "def extract_dialogue_turns(conversation):\n",
        "    dialogue_turns = []\n",
        "    lines = conversation.split('\\n')\n",
        "    current_speaker = None\n",
        "    current_line = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "\n",
        "        if re.match(r'^[A-Z]+$', line):\n",
        "            # Save previous dialogue if exists\n",
        "            if current_speaker and current_line:\n",
        "                dialogue_turns.append({\n",
        "                    \"speaker\": current_speaker,\n",
        "                    \"text_roman\": current_line.strip(),\n",
        "                    \"text_devanagari\": transliterate_to_devanagari(current_line.strip())\n",
        "                })\n",
        "\n",
        "            current_speaker = line\n",
        "            current_line = \"\"\n",
        "        else:\n",
        "\n",
        "            current_line += \" \" + line\n",
        "\n",
        "\n",
        "    if current_speaker and current_line:\n",
        "        dialogue_turns.append({\n",
        "            \"speaker\": current_speaker,\n",
        "            \"text_roman\": current_line.strip(),\n",
        "            \"text_devanagari\": transliterate_to_devanagari(current_line.strip())\n",
        "        })\n",
        "\n",
        "    return dialogue_turns\n",
        "\n",
        "\n",
        "def generate_scene_descriptions_batch(dialogue_batch, text_generator, max_batch_size=8):\n",
        "    results = []\n",
        "    # Process in smaller batches to avoid CUDA memory issues\n",
        "    for i in range(0, len(dialogue_batch), max_batch_size):\n",
        "        sub_batch = dialogue_batch[i:i+max_batch_size]\n",
        "\n",
        "        prompts = []\n",
        "        for dialogue_turns in sub_batch:\n",
        "            # Join all dialogue text\n",
        "            dialogue_text = \"\\n\".join([f\"{turn['speaker']}: {turn['text_roman']}\" for turn in dialogue_turns])\n",
        "\n",
        "            # Truncate if too long\n",
        "            max_length = 512\n",
        "            if len(dialogue_text) > max_length:\n",
        "                dialogue_text = dialogue_text[:max_length]\n",
        "\n",
        "            # Generate prompt for the model\n",
        "            prompt = f\"Based on this Hindi movie dialogue, describe the scene, setting, and emotional context in one paragraph:\\n\\n{dialogue_text}\\n\\nScene description:\"\n",
        "            prompts.append(prompt)\n",
        "\n",
        "        try:\n",
        "            # Generate descriptions for the batch\n",
        "            batch_results = text_generator(prompts, max_length=150, batch_size=len(prompts))\n",
        "\n",
        "            # Extract generated texts\n",
        "            for result in batch_results:\n",
        "                if isinstance(result, list):\n",
        "                    results.append(result[0]['generated_text'])\n",
        "                else:\n",
        "                    results.append(result['generated_text'])\n",
        "        except Exception as e:\n",
        "            print(f\"Scene description generation error in batch: {e}\")\n",
        "            # Fall back to default descriptions for this batch\n",
        "            for _ in range(len(sub_batch)):\n",
        "                results.append(\"Scene description not available.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Function to extract emotion tags from dialogue content\n",
        "def extract_emotion_tags(dialogue_turns):\n",
        "    # Common Hindi emotional phrases and their corresponding tags\n",
        "    emotion_patterns = {\n",
        "        'angry': [r'gussa', r'naraz', r'krodh', r'chillana'],\n",
        "        'happy': [r'khush', r'maza', r'anand', r'hasi', r'muskurana'],\n",
        "        'sad': [r'dukh', r'udas', r'rona', r'aansu'],\n",
        "        'surprised': [r'achanak', r'hairani', r'aashcharya'],\n",
        "        'scared': [r'dar', r'bhay', r'ghabrana'],\n",
        "        'romantic': [r'pyar', r'ishq', r'mohabbat', r'prem'],\n",
        "        'serious': [r'gambhir', r'sanjeeda'],\n",
        "        'confused': [r'confusion', r'samajh', r'uljhan']\n",
        "    }\n",
        "\n",
        "    full_text = \" \".join([turn[\"text_roman\"].lower() for turn in dialogue_turns])\n",
        "\n",
        "    detected_emotions = []\n",
        "    for emotion, patterns in emotion_patterns.items():\n",
        "        for pattern in patterns:\n",
        "            if re.search(pattern, full_text, re.IGNORECASE):\n",
        "                detected_emotions.append(emotion)\n",
        "                break\n",
        "\n",
        "    return list(set(detected_emotions))\n",
        "\n",
        "# Function to extract context tags based on dialogue content\n",
        "def extract_context_tags(dialogue_turns):\n",
        "    # Common Hindi contextual phrases and their corresponding tags\n",
        "    context_patterns = {\n",
        "        'family': [r'maa', r'baap', r'papa', r'mata', r'pita', r'bhai', r'behen', r'chacha', r'chachi', r'parivar'],\n",
        "        'romance': [r'pyar', r'ishq', r'mohabbat', r'prem', r'dil', r'shadi'],\n",
        "        'friendship': [r'dost', r'yaar', r'mitra', r'saathi'],\n",
        "        'work': [r'kaam', r'naukri', r'office', r'boss', r'business'],\n",
        "        'education': [r'school', r'college', r'padhai', r'kitab', r'teacher', r'professor'],\n",
        "        'conflict': [r'ladai', r'jhagda', r'bahas', r'jung'],\n",
        "        'food': [r'khana', r'restaurant', r'bhojan', r'roti', r'chai'],\n",
        "        'travel': [r'safar', r'yatra', r'ghoomna', r'train', r'bus', r'car'],\n",
        "        'shopping': [r'bazaar', r'dukan', r'kharidna', r'price', r'kimat'],\n",
        "        'health': [r'bimari', r'doctor', r'hospital', r'tabiyat', r'dawa']\n",
        "    }\n",
        "\n",
        "    full_text = \" \".join([turn[\"text_roman\"].lower() for turn in dialogue_turns])\n",
        "\n",
        "    detected_contexts = []\n",
        "    for context, patterns in context_patterns.items():\n",
        "        for pattern in patterns:\n",
        "            if re.search(pattern, full_text, re.IGNORECASE):\n",
        "                detected_contexts.append(context)\n",
        "                break\n",
        "\n",
        "    return list(set(detected_contexts))\n",
        "\n",
        "# Function to extract characters and their relationships\n",
        "def extract_character_relationships(dialogue_turns):\n",
        "    speakers = [turn[\"speaker\"] for turn in dialogue_turns]\n",
        "    unique_speakers = list(set(speakers))\n",
        "\n",
        "    # Count speaker interactions\n",
        "    interactions = {}\n",
        "    for i in range(len(dialogue_turns) - 1):\n",
        "        current_speaker = dialogue_turns[i][\"speaker\"]\n",
        "        next_speaker = dialogue_turns[i + 1][\"speaker\"]\n",
        "\n",
        "        if current_speaker != next_speaker:\n",
        "            pair = tuple(sorted([current_speaker, next_speaker]))\n",
        "            interactions[pair] = interactions.get(pair, 0) + 1\n",
        "\n",
        "    # Create relationships dictionary\n",
        "    relationships = {}\n",
        "    for speaker in unique_speakers:\n",
        "        relationships[speaker] = []\n",
        "        for pair, count in interactions.items():\n",
        "            if speaker in pair:\n",
        "                other_speaker = pair[0] if pair[1] == speaker else pair[1]\n",
        "                relationships[speaker].append({\"character\": other_speaker, \"interaction_count\": count})\n",
        "\n",
        "    return relationships\n",
        "\n",
        "# Generate a default scene description based on emotion and context tags\n",
        "def generate_default_scene_description(emotion_tags, context_tags, dialogue_turns):\n",
        "    speakers = list(set([turn[\"speaker\"] for turn in dialogue_turns]))\n",
        "    speaker_str = \", \".join(speakers[:3])\n",
        "    if len(speakers) > 3:\n",
        "        speaker_str += f\" and {len(speakers) - 3} others\"\n",
        "\n",
        "    emotion_str = \", \".join(emotion_tags) if emotion_tags else \"neutral\"\n",
        "    context_str = \", \".join(context_tags) if context_tags else \"general conversation\"\n",
        "\n",
        "    return f\"A {emotion_str} scene involving {speaker_str} in a {context_str} context. The characters are engaged in dialogue that reveals their relationships and intentions.\"\n",
        "\n",
        "# Process a batch of scenes\n",
        "def process_batch(batch, use_pipeline=False, text_generator=None):\n",
        "    processed_docs = []\n",
        "\n",
        "    # Extract dialogue turns for all scenes in batch\n",
        "    dialogue_turns_list = []\n",
        "    scene_metadata = []\n",
        "\n",
        "    for scene in batch:\n",
        "        # Extract basic metadata\n",
        "        scene_id = scene.get(\"ID\", \"unknown\")\n",
        "        movie_id = scene.get(\"Movie\", \"unknown\")\n",
        "\n",
        "        # Clean conversation text\n",
        "        conversation = scene.get(\"Conversation\", \"\")\n",
        "\n",
        "        # Extract dialogue turns with speaker information\n",
        "        dialogue_turns = extract_dialogue_turns(conversation)\n",
        "\n",
        "        if not dialogue_turns:\n",
        "            continue\n",
        "\n",
        "        dialogue_turns_list.append(dialogue_turns)\n",
        "        scene_metadata.append((scene_id, movie_id))\n",
        "\n",
        "    # Generate scene descriptions in batch if using pipeline\n",
        "    if use_pipeline and text_generator and dialogue_turns_list:\n",
        "        try:\n",
        "            scene_descriptions = generate_scene_descriptions_batch(dialogue_turns_list, text_generator)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed batch scene description generation: {e}\")\n",
        "            scene_descriptions = [None] * len(dialogue_turns_list)\n",
        "    else:\n",
        "        scene_descriptions = [None] * len(dialogue_turns_list)\n",
        "\n",
        "    # Process the rest of the metadata and create documents\n",
        "    for i, dialogue_turns in enumerate(dialogue_turns_list):\n",
        "        scene_id, movie_id = scene_metadata[i]\n",
        "\n",
        "        # Extract emotion and context tags\n",
        "        emotion_tags = extract_emotion_tags(dialogue_turns)\n",
        "        context_tags = extract_context_tags(dialogue_turns)\n",
        "\n",
        "        # Use generated scene description or fall back to default\n",
        "        if use_pipeline and scene_descriptions[i]:\n",
        "            scene_description = scene_descriptions[i]\n",
        "        else:\n",
        "            scene_description = generate_default_scene_description(emotion_tags, context_tags, dialogue_turns)\n",
        "\n",
        "        # Extract character relationships\n",
        "        character_relationships = extract_character_relationships(dialogue_turns)\n",
        "\n",
        "        # Create text versions\n",
        "        roman_dialogue = \"\\n\".join([f\"{turn['speaker']}: {turn['text_roman']}\" for turn in dialogue_turns])\n",
        "        devanagari_dialogue = \"\\n\".join([f\"{turn['speaker']}: {turn['text_devanagari']}\" for turn in dialogue_turns])\n",
        "        combined_dialogue = \"\\n\".join([\n",
        "            f\"{turn['speaker']}: {turn['text_roman']}\\n{turn['speaker']} (देवनागरी): {turn['text_devanagari']}\"\n",
        "            for turn in dialogue_turns\n",
        "        ])\n",
        "\n",
        "        # Create document\n",
        "        doc = Document(\n",
        "            page_content=combined_dialogue,\n",
        "            metadata={\n",
        "                \"scene_id\": scene_id,\n",
        "                \"movie_id\": movie_id,\n",
        "                \"scene_description\": scene_description,\n",
        "                \"speakers\": [turn[\"speaker\"] for turn in dialogue_turns],\n",
        "                \"emotion_tags\": emotion_tags,\n",
        "                \"context_tags\": context_tags,\n",
        "                \"character_relationships\": character_relationships,\n",
        "                \"roman_dialogue\": roman_dialogue,\n",
        "                \"devanagari_dialogue\": devanagari_dialogue,\n",
        "                \"dialogue_turns\": [\n",
        "                    {\n",
        "                        \"speaker\": turn[\"speaker\"],\n",
        "                        \"text_roman\": turn[\"text_roman\"],\n",
        "                        \"text_devanagari\": turn[\"text_devanagari\"]\n",
        "                    } for turn in dialogue_turns\n",
        "                ]\n",
        "            }\n",
        "        )\n",
        "\n",
        "        processed_docs.append(doc)\n",
        "\n",
        "    return processed_docs\n",
        "\n",
        "# Main preprocessing function with GPU optimizations\n",
        "def preprocess_movie_dialogues(data, use_pipeline=False, batch_size=16, num_workers=2):\n",
        "    # Create dataset and dataloader for parallel processing\n",
        "    dataset = DialogueSceneDataset(data)\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        collate_fn=lambda x: x  # Don't collate, just return list of scenes\n",
        "    )\n",
        "\n",
        "    processed_documents = []\n",
        "\n",
        "    # Set up pipeline if needed\n",
        "    text_generator = None\n",
        "    if use_pipeline:\n",
        "        try:\n",
        "            # Use 8-bit quantization to reduce GPU memory usage while maintaining quality\n",
        "            text_generator = pipeline(\n",
        "                'text2text-generation',\n",
        "                model='google/flan-t5-small',\n",
        "                device=0 if torch.cuda.is_available() else -1,\n",
        "                model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float16}\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load text generation pipeline: {e}\")\n",
        "            use_pipeline = False\n",
        "\n",
        "    # Process in batches\n",
        "    print(f\"Processing {len(data)} scenes in batches of {batch_size}...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, batch in enumerate(tqdm(dataloader, desc=\"Processing batches\")):\n",
        "        # Process batch\n",
        "        batch_docs = process_batch(batch, use_pipeline, text_generator)\n",
        "        processed_documents.extend(batch_docs)\n",
        "\n",
        "        # Periodically clear CUDA cache to avoid memory issues\n",
        "        if torch.cuda.is_available() and i % 10 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"Preprocessing complete! Processed {len(processed_documents)} scenes in {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Average time per scene: {elapsed_time/len(processed_documents):.2f} seconds\")\n",
        "\n",
        "    return processed_documents\n",
        "\n",
        "# Function to save processed documents to JSON with incremental saving\n",
        "def save_processed_data(processed_documents, output_file, batch_size=1000):\n",
        "    print(f\"Saving {len(processed_documents)} documents to {output_file}...\")\n",
        "\n",
        "    # Process and save in batches to reduce memory usage\n",
        "    total_batches = (len(processed_documents) + batch_size - 1) // batch_size\n",
        "\n",
        "    for batch_idx in tqdm(range(total_batches), desc=\"Saving batches\"):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, len(processed_documents))\n",
        "        batch = processed_documents[start_idx:end_idx]\n",
        "\n",
        "        # Convert Document objects to serializable dictionary\n",
        "        serializable_docs = []\n",
        "        for doc in batch:\n",
        "            # Create a serializable version of metadata\n",
        "            serializable_metadata = {}\n",
        "            for key, value in doc.metadata.items():\n",
        "                # Handle special cases like dialogue_turns that might contain non-serializable objects\n",
        "                if key == \"dialogue_turns\":\n",
        "                    serializable_metadata[key] = [\n",
        "                        {\n",
        "                            \"speaker\": turn[\"speaker\"],\n",
        "                            \"text_roman\": turn[\"text_roman\"],\n",
        "                            \"text_devanagari\": turn[\"text_devanagari\"]\n",
        "                        } for turn in value\n",
        "                    ]\n",
        "                elif key == \"character_relationships\":\n",
        "                    # Convert to a simpler format if needed\n",
        "                    serializable_metadata[key] = {k: [vars(item) if not isinstance(item, dict) else item for item in v]\n",
        "                                                for k, v in value.items()}\n",
        "                else:\n",
        "                    serializable_metadata[key] = value\n",
        "\n",
        "            serializable_doc = {\n",
        "                \"page_content\": doc.page_content,\n",
        "                \"metadata\": serializable_metadata\n",
        "            }\n",
        "            serializable_docs.append(serializable_doc)\n",
        "\n",
        "        # Determine whether to write or append\n",
        "        if batch_idx == 0:\n",
        "            # First batch, create new file\n",
        "            with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                # Write opening bracket for JSON array\n",
        "                f.write(\"[\\n\")\n",
        "                # Write documents with comma separation\n",
        "                for i, doc in enumerate(serializable_docs):\n",
        "                    json_str = json.dumps(doc, ensure_ascii=False, indent=2)\n",
        "                    if i < len(serializable_docs) - 1 or total_batches > 1:\n",
        "                        f.write(json_str + \",\\n\")\n",
        "                    else:\n",
        "                        f.write(json_str + \"\\n\")\n",
        "        elif batch_idx == total_batches - 1:\n",
        "            # Last batch, complete the file\n",
        "            with open(output_file, 'a', encoding='utf-8') as f:\n",
        "                # Write documents with comma separation\n",
        "                for i, doc in enumerate(serializable_docs):\n",
        "                    json_str = json.dumps(doc, ensure_ascii=False, indent=2)\n",
        "                    if i < len(serializable_docs) - 1:\n",
        "                        f.write(json_str + \",\\n\")\n",
        "                    else:\n",
        "                        f.write(json_str + \"\\n\")\n",
        "                # Write closing bracket for JSON array\n",
        "                f.write(\"]\\n\")\n",
        "        else:\n",
        "            # Middle batch, append to file\n",
        "            with open(output_file, 'a', encoding='utf-8') as f:\n",
        "                # Write documents with comma separation\n",
        "                for doc in serializable_docs:\n",
        "                    json_str = json.dumps(doc, ensure_ascii=False, indent=2)\n",
        "                    f.write(json_str + \",\\n\")\n",
        "\n",
        "        # Clear memory\n",
        "        del serializable_docs\n",
        "        gc.collect()\n",
        "\n",
        "# Function to create vector store for RAG with GPU acceleration\n",
        "def create_vector_store(processed_documents, index_name, batch_size=500):\n",
        "    # Determine if we have enough GPU memory\n",
        "    use_gpu = torch.cuda.is_available() and torch.cuda.get_device_properties(0).total_memory > 8e9  # 8GB\n",
        "\n",
        "    device = 'cuda' if use_gpu else 'cpu'\n",
        "    print(f\"Creating FAISS index on {device}...\")\n",
        "\n",
        "    # Create embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"ai4bharat/indic-bert\",\n",
        "        model_kwargs={\"device\": device},\n",
        "        encode_kwargs={\"device\": device, \"batch_size\": 32}\n",
        "    )\n",
        "\n",
        "    # Process in batches to manage memory\n",
        "    vector_store = None\n",
        "\n",
        "    for i in tqdm(range(0, len(processed_documents), batch_size), desc=\"Creating vector index batches\"):\n",
        "        batch = processed_documents[i:i+batch_size]\n",
        "\n",
        "        if vector_store is None:\n",
        "            # First batch, create the store\n",
        "            vector_store = FAISS.from_documents(batch, embeddings)\n",
        "        else:\n",
        "            # Subsequent batches, add to existing store\n",
        "            batch_vector_store = FAISS.from_documents(batch, embeddings)\n",
        "            vector_store.merge_from(batch_vector_store)\n",
        "\n",
        "        # Clear GPU memory\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Save the index\n",
        "    print(f\"Saving vector store to {index_name}...\")\n",
        "    vector_store.save_local(index_name)\n",
        "    return vector_store\n",
        "\n",
        "def print_gpu_info():\n",
        "    if torch.cuda.is_available():\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            device = torch.cuda.get_device_properties(i)\n",
        "            print(f\"GPU {i}: {device.name}\")\n",
        "            print(f\"  Memory: {device.total_memory / 1e9:.2f} GB\")\n",
        "            mem = torch.cuda.memory_allocated(i) / 1e9\n",
        "            print(f\"  Memory Allocated: {mem:.2f} GB\")\n",
        "            mem = torch.cuda.memory_reserved(i) / 1e9\n",
        "            print(f\"  Memory Reserved: {mem:.2f} GB\")\n",
        "            mem = torch.cuda.max_memory_allocated(i) / 1e9\n",
        "            print(f\"  Max Memory Allocated: {mem:.2f} GB\")\n",
        "    else:\n",
        "        print(\"No GPU available\")\n",
        "\n",
        "=\n",
        "def main():\n",
        "\n",
        "    print(\"System Information:\")\n",
        "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "    print(f\"PyTorch Version: {torch.__version__}\")\n",
        "    print_gpu_info()\n",
        "\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "\n",
        "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # in GB\n",
        "        batch_size = int(max(8, min(32, gpu_memory / 0.5)))  # Each scene might use ~0.5GB\n",
        "        num_workers = min(4, os.cpu_count() or 1)\n",
        "    else:\n",
        "        batch_size = 8\n",
        "        num_workers = 1\n",
        "\n",
        "    print(f\"Using batch size: {batch_size}, num_workers: {num_workers}\")\n",
        "\n",
        "    # Set device (GPU if available, else CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "    use_pipeline = False\n",
        "    try:\n",
        "        # Test if pipeline works\n",
        "        print(\"Testing text generation pipeline...\")\n",
        "        test_pipeline = pipeline(\n",
        "            'text2text-generation',\n",
        "            model='google/flan-t5-small',\n",
        "            device=0 if torch.cuda.is_available() else -1,\n",
        "            model_kwargs={\"device_map\": \"auto\", \"torch_dtype\": torch.float16}\n",
        "        )\n",
        "        test_result = test_pipeline(\"Test\", max_length=10)\n",
        "        print(\"Pipeline test successful!\")\n",
        "        use_pipeline = True\n",
        "\n",
        "        # Clear memory after test\n",
        "        del test_pipeline\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load text generation pipeline: {e}\")\n",
        "        print(\"Will use default scene descriptions instead.\")\n",
        "        input_file = \"/kaggle/input/movie-dialogues/Final_Key.json\"\n",
        "    output_file = \"/kaggle/working/processed_hindi_dialogues.json\"\n",
        "    index_name = \"hindi_dialogue_faiss_index\"\n",
        "\n",
        "\n",
        "    print(\"Loading movie dialogue data...\")\n",
        "    data = load_movie_dialogues(input_file)\n",
        "\n",
        "    print(\"Preprocessing movie dialogues...\")\n",
        "    processed_documents = preprocess_movie_dialogues(\n",
        "        data,\n",
        "        use_pipeline=use_pipeline,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "\n",
        "    print(\"Saving processed data...\")\n",
        "    save_processed_data(processed_documents, output_file)\n",
        "\n",
        "    print(\"Creating vector store for RAG...\")\n",
        "    vector_store = create_vector_store(processed_documents, index_name)\n",
        "\n",
        "    print(\"Preprocessing complete!\")\n",
        "    print(f\"Processed {len(processed_documents)} scenes.\")\n",
        "    print(f\"Saved processed data to {output_file}\")\n",
        "    print(f\"Saved vector store to {index_name}\")\n",
        "    print_gpu_info()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-08T06:29:50.691915Z",
          "iopub.execute_input": "2025-03-08T06:29:50.692278Z",
          "iopub.status.idle": "2025-03-08T06:30:35.219763Z",
          "shell.execute_reply.started": "2025-03-08T06:29:50.692249Z",
          "shell.execute_reply": "2025-03-08T06:30:35.21904Z"
        },
        "id": "jupKmxZFvldM",
        "outputId": "6d46ca4a-7571-472a-ebaf-49df9e7b81fe",
        "colab": {
          "referenced_widgets": [
            "799f7c8c15864ffa8fe3840ee9acc63a",
            "e2f3e8e7965c4b74942118a2ee9594a7",
            "378d4b59d0fe4e2cb57ad1f0ad6796db"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "System Information:\nCUDA Available: True\nPyTorch Version: 2.5.1+cu121\nGPU 0: Tesla T4\n  Memory: 15.83 GB\n  Memory Allocated: 0.45 GB\n  Memory Reserved: 0.48 GB\n  Max Memory Allocated: 1.05 GB\nGPU 1: Tesla T4\n  Memory: 15.83 GB\n  Memory Allocated: 0.00 GB\n  Memory Reserved: 0.00 GB\n  Max Memory Allocated: 0.12 GB\nUsing batch size: 31, num_workers: 4\nUsing device: cuda\nTesting text generation pipeline...\nFailed to load text generation pipeline: The model has been loaded with `accelerate` and therefore cannot be moved to a specific device. Please discard the `device` argument when creating your pipeline object.\nWill use default scene descriptions instead.\nLoading movie dialogue data...\nPreprocessing movie dialogues...\nProcessing 1811 scenes in batches of 31...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Processing batches:   0%|          | 0/59 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "799f7c8c15864ffa8fe3840ee9acc63a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Preprocessing complete! Processed 1642 scenes in 5.04 seconds\nAverage time per scene: 0.00 seconds\nSaving processed data...\nSaving 1642 documents to /kaggle/working/processed_hindi_dialogues.json...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Saving batches:   0%|          | 0/2 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2f3e8e7965c4b74942118a2ee9594a7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Creating vector store for RAG...\nCreating FAISS index on cuda...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Creating vector index batches:   0%|          | 0/4 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "378d4b59d0fe4e2cb57ad1f0ad6796db"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Saving vector store to hindi_dialogue_faiss_index...\nPreprocessing complete!\nProcessed 1642 scenes.\nSaved processed data to /kaggle/working/processed_hindi_dialogues.json\nSaved vector store to hindi_dialogue_faiss_index\nGPU 0: Tesla T4\n  Memory: 15.83 GB\n  Memory Allocated: 0.45 GB\n  Memory Reserved: 0.48 GB\n  Max Memory Allocated: 1.05 GB\nGPU 1: Tesla T4\n  Memory: 15.83 GB\n  Memory Allocated: 0.00 GB\n  Memory Reserved: 0.00 GB\n  Max Memory Allocated: 0.12 GB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the required library\n",
        "!pip install indic-transliteration --quiet"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-08T06:26:41.945102Z",
          "iopub.execute_input": "2025-03-08T06:26:41.945433Z",
          "iopub.status.idle": "2025-03-08T06:26:45.87348Z",
          "shell.execute_reply.started": "2025-03-08T06:26:41.945405Z",
          "shell.execute_reply": "2025-03-08T06:26:45.872632Z"
        },
        "id": "3wu9FBXxvldP",
        "outputId": "bd7f878a-2f34-4f9c-e53f-a8ffa83ef2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "6gC78HnevldP"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}